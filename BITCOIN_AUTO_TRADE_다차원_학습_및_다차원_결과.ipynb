{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "15Q5EWfUGI268zyt52t_Oa3tl6b6xOxQX",
      "authorship_tag": "ABX9TyNCbzzO5fOjHvHyJ74Lq3ae",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agape1225/BITCOIN-AUTO-TRADE-SERVER/blob/main/BITCOIN_AUTO_TRADE_%EB%8B%A4%EC%B0%A8%EC%9B%90_%ED%95%99%EC%8A%B5_%EB%B0%8F_%EB%8B%A4%EC%B0%A8%EC%9B%90_%EA%B2%B0%EA%B3%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1I6U3hOJ4hXF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For Evalution we will use these library\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n",
        "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# For model building we will use these library\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "\n",
        "# For PLotting we will use these library\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "maindf = pd.read_csv('BTC_KRW.csv')\n",
        "maindf = maindf.iloc[::-1]\n",
        "\n",
        "# 필요한 열 선택\n",
        "closedf = maindf[['시가', '종가', '고가', '저가', '거래량']]\n",
        "\n",
        "# 데이터 전처리\n",
        "closedf['종가'] = closedf['종가'].str.replace(',', '').astype(float).copy()\n",
        "closedf['시가'] = closedf['시가'].str.replace(',', '').astype(float).copy()\n",
        "closedf['고가'] = closedf['고가'].str.replace(',', '').astype(float).copy()\n",
        "closedf['저가'] = closedf['저가'].str.replace(',', '').astype(float).copy()\n",
        "closedf['거래량'] = closedf['거래량'].str.replace('K', '').astype(float).copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdv6JBh6B2Av",
        "outputId": "2d120208-0ba6-4f83-e1f9-553eb4e83458"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-b52f40b8e3e9>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  closedf['종가'] = closedf['종가'].str.replace(',', '').astype(float).copy()\n",
            "<ipython-input-2-b52f40b8e3e9>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  closedf['시가'] = closedf['시가'].str.replace(',', '').astype(float).copy()\n",
            "<ipython-input-2-b52f40b8e3e9>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  closedf['고가'] = closedf['고가'].str.replace(',', '').astype(float).copy()\n",
            "<ipython-input-2-b52f40b8e3e9>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  closedf['저가'] = closedf['저가'].str.replace(',', '').astype(float).copy()\n",
            "<ipython-input-2-b52f40b8e3e9>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  closedf['거래량'] = closedf['거래량'].str.replace('K', '').astype(float).copy()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 정규화\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "closedf = scaler.fit_transform(closedf)\n",
        "\n",
        "# 데이터 분할\n",
        "training_size = int(len(closedf) * 0.60)\n",
        "test_size = len(closedf) - training_size\n",
        "train_data, test_data = closedf[0:training_size, :], closedf[training_size:len(closedf), :]"
      ],
      "metadata": {
        "id": "cwBa0Yi-CvqD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시계열 데이터셋 생성 함수\n",
        "def create_dataset(dataset, time_step=1, target_num=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset) - time_step - target_num):\n",
        "        a = dataset[i:(i+time_step), :]\n",
        "        b = dataset[i + time_step : i + time_step + target_num, 1]\n",
        "\n",
        "        dataX.append(a)\n",
        "        dataY.append(b)\n",
        "\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "# 시계열 데이터셋 생성\n",
        "time_step = 60\n",
        "target_num = 8\n",
        "X_train, y_train = create_dataset(train_data, time_step, target_num)\n",
        "X_test, y_test = create_dataset(test_data, time_step, target_num)"
      ],
      "metadata": {
        "id": "TR76FkgWCxc1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터의 차원을 3차원으로 변경\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2])"
      ],
      "metadata": {
        "id": "aKLNr_l4Fpu0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM 모델 정의 및 학습\n",
        "model = Sequential()\n",
        "model.add(LSTM(40, input_shape=(X_train.shape[1], X_train.shape[2]), activation=\"tanh\"))\n",
        "model.add(Dense(target_num))\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=300, batch_size=512, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-3XXoZwF6Az",
        "outputId": "fe71ef9e-2c4f-429d-9800-327c611ca175"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "3/3 [==============================] - 4s 248ms/step - loss: 0.0294 - val_loss: 0.2931\n",
            "Epoch 2/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0229 - val_loss: 0.2355\n",
            "Epoch 3/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0174 - val_loss: 0.1825\n",
            "Epoch 4/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0129 - val_loss: 0.1306\n",
            "Epoch 5/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0087 - val_loss: 0.0802\n",
            "Epoch 6/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0374\n",
            "Epoch 7/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0043 - val_loss: 0.0141\n",
            "Epoch 8/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0038 - val_loss: 0.0079\n",
            "Epoch 9/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - val_loss: 0.0069\n",
            "Epoch 10/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0024 - val_loss: 0.0063\n",
            "Epoch 11/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0019 - val_loss: 0.0077\n",
            "Epoch 12/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0014 - val_loss: 0.0182\n",
            "Epoch 13/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0013 - val_loss: 0.0251\n",
            "Epoch 14/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0012 - val_loss: 0.0164\n",
            "Epoch 15/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0011 - val_loss: 0.0124\n",
            "Epoch 16/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0011 - val_loss: 0.0145\n",
            "Epoch 17/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.9308e-04 - val_loss: 0.0191\n",
            "Epoch 18/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 9.6206e-04 - val_loss: 0.0173\n",
            "Epoch 19/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 9.0079e-04 - val_loss: 0.0114\n",
            "Epoch 20/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 8.7768e-04 - val_loss: 0.0090\n",
            "Epoch 21/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 8.7678e-04 - val_loss: 0.0094\n",
            "Epoch 22/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 8.5719e-04 - val_loss: 0.0109\n",
            "Epoch 23/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.4712e-04 - val_loss: 0.0114\n",
            "Epoch 24/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.3597e-04 - val_loss: 0.0110\n",
            "Epoch 25/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.1823e-04 - val_loss: 0.0099\n",
            "Epoch 26/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 8.0773e-04 - val_loss: 0.0095\n",
            "Epoch 27/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.9807e-04 - val_loss: 0.0104\n",
            "Epoch 28/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.8933e-04 - val_loss: 0.0109\n",
            "Epoch 29/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 7.8640e-04 - val_loss: 0.0105\n",
            "Epoch 30/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.8022e-04 - val_loss: 0.0094\n",
            "Epoch 31/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 7.7125e-04 - val_loss: 0.0092\n",
            "Epoch 32/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.6522e-04 - val_loss: 0.0093\n",
            "Epoch 33/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.5958e-04 - val_loss: 0.0090\n",
            "Epoch 34/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.5436e-04 - val_loss: 0.0087\n",
            "Epoch 35/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 7.4961e-04 - val_loss: 0.0084\n",
            "Epoch 36/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.4601e-04 - val_loss: 0.0081\n",
            "Epoch 37/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.4263e-04 - val_loss: 0.0081\n",
            "Epoch 38/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 7.3655e-04 - val_loss: 0.0086\n",
            "Epoch 39/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.3263e-04 - val_loss: 0.0092\n",
            "Epoch 40/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.3097e-04 - val_loss: 0.0089\n",
            "Epoch 41/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.2498e-04 - val_loss: 0.0080\n",
            "Epoch 42/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.2110e-04 - val_loss: 0.0075\n",
            "Epoch 43/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.1865e-04 - val_loss: 0.0076\n",
            "Epoch 44/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.1493e-04 - val_loss: 0.0084\n",
            "Epoch 45/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.1238e-04 - val_loss: 0.0081\n",
            "Epoch 46/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.0671e-04 - val_loss: 0.0080\n",
            "Epoch 47/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 7.0345e-04 - val_loss: 0.0080\n",
            "Epoch 48/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.0349e-04 - val_loss: 0.0074\n",
            "Epoch 49/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.9718e-04 - val_loss: 0.0077\n",
            "Epoch 50/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.9399e-04 - val_loss: 0.0076\n",
            "Epoch 51/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 6.8908e-04 - val_loss: 0.0068\n",
            "Epoch 52/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 6.8873e-04 - val_loss: 0.0066\n",
            "Epoch 53/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.8624e-04 - val_loss: 0.0075\n",
            "Epoch 54/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.8153e-04 - val_loss: 0.0072\n",
            "Epoch 55/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.8020e-04 - val_loss: 0.0068\n",
            "Epoch 56/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 6.7374e-04 - val_loss: 0.0076\n",
            "Epoch 57/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.7864e-04 - val_loss: 0.0080\n",
            "Epoch 58/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 6.6903e-04 - val_loss: 0.0066\n",
            "Epoch 59/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 6.6798e-04 - val_loss: 0.0061\n",
            "Epoch 60/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 6.6504e-04 - val_loss: 0.0068\n",
            "Epoch 61/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 6.6361e-04 - val_loss: 0.0074\n",
            "Epoch 62/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.5855e-04 - val_loss: 0.0065\n",
            "Epoch 63/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 6.5605e-04 - val_loss: 0.0059\n",
            "Epoch 64/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 6.5375e-04 - val_loss: 0.0063\n",
            "Epoch 65/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 6.5592e-04 - val_loss: 0.0074\n",
            "Epoch 66/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 6.5102e-04 - val_loss: 0.0064\n",
            "Epoch 67/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 6.4484e-04 - val_loss: 0.0061\n",
            "Epoch 68/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.4175e-04 - val_loss: 0.0066\n",
            "Epoch 69/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 6.3836e-04 - val_loss: 0.0065\n",
            "Epoch 70/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.3575e-04 - val_loss: 0.0067\n",
            "Epoch 71/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 6.3344e-04 - val_loss: 0.0066\n",
            "Epoch 72/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.3295e-04 - val_loss: 0.0069\n",
            "Epoch 73/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 6.2824e-04 - val_loss: 0.0061\n",
            "Epoch 74/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 6.2986e-04 - val_loss: 0.0057\n",
            "Epoch 75/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 6.2319e-04 - val_loss: 0.0065\n",
            "Epoch 76/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 6.2185e-04 - val_loss: 0.0066\n",
            "Epoch 77/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 6.1990e-04 - val_loss: 0.0066\n",
            "Epoch 78/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 6.1637e-04 - val_loss: 0.0060\n",
            "Epoch 79/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 6.1534e-04 - val_loss: 0.0059\n",
            "Epoch 80/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.1043e-04 - val_loss: 0.0054\n",
            "Epoch 81/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 6.1003e-04 - val_loss: 0.0056\n",
            "Epoch 82/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.0472e-04 - val_loss: 0.0064\n",
            "Epoch 83/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 6.0521e-04 - val_loss: 0.0064\n",
            "Epoch 84/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.0311e-04 - val_loss: 0.0060\n",
            "Epoch 85/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 5.9773e-04 - val_loss: 0.0056\n",
            "Epoch 86/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 5.9648e-04 - val_loss: 0.0057\n",
            "Epoch 87/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 5.9572e-04 - val_loss: 0.0060\n",
            "Epoch 88/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 5.9123e-04 - val_loss: 0.0068\n",
            "Epoch 89/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 5.9152e-04 - val_loss: 0.0062\n",
            "Epoch 90/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 5.8650e-04 - val_loss: 0.0054\n",
            "Epoch 91/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 5.8539e-04 - val_loss: 0.0054\n",
            "Epoch 92/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 5.8287e-04 - val_loss: 0.0060\n",
            "Epoch 93/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 5.7918e-04 - val_loss: 0.0057\n",
            "Epoch 94/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 5.7758e-04 - val_loss: 0.0052\n",
            "Epoch 95/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 5.7667e-04 - val_loss: 0.0058\n",
            "Epoch 96/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 5.7094e-04 - val_loss: 0.0054\n",
            "Epoch 97/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 5.6932e-04 - val_loss: 0.0052\n",
            "Epoch 98/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 5.6732e-04 - val_loss: 0.0058\n",
            "Epoch 99/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 5.6385e-04 - val_loss: 0.0056\n",
            "Epoch 100/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 5.6237e-04 - val_loss: 0.0050\n",
            "Epoch 101/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 5.6075e-04 - val_loss: 0.0054\n",
            "Epoch 102/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 5.5577e-04 - val_loss: 0.0052\n",
            "Epoch 103/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 5.5378e-04 - val_loss: 0.0054\n",
            "Epoch 104/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 5.4956e-04 - val_loss: 0.0058\n",
            "Epoch 105/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 5.4816e-04 - val_loss: 0.0059\n",
            "Epoch 106/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 5.4776e-04 - val_loss: 0.0055\n",
            "Epoch 107/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 5.4466e-04 - val_loss: 0.0062\n",
            "Epoch 108/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 5.4000e-04 - val_loss: 0.0054\n",
            "Epoch 109/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 5.3950e-04 - val_loss: 0.0052\n",
            "Epoch 110/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 5.3382e-04 - val_loss: 0.0061\n",
            "Epoch 111/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 5.3459e-04 - val_loss: 0.0055\n",
            "Epoch 112/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 5.2758e-04 - val_loss: 0.0054\n",
            "Epoch 113/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 5.2443e-04 - val_loss: 0.0053\n",
            "Epoch 114/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 5.2218e-04 - val_loss: 0.0060\n",
            "Epoch 115/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 5.1789e-04 - val_loss: 0.0055\n",
            "Epoch 116/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 5.1386e-04 - val_loss: 0.0058\n",
            "Epoch 117/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 5.1201e-04 - val_loss: 0.0061\n",
            "Epoch 118/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 5.0758e-04 - val_loss: 0.0052\n",
            "Epoch 119/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 5.0469e-04 - val_loss: 0.0049\n",
            "Epoch 120/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 5.0323e-04 - val_loss: 0.0057\n",
            "Epoch 121/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 4.9708e-04 - val_loss: 0.0058\n",
            "Epoch 122/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 4.9262e-04 - val_loss: 0.0063\n",
            "Epoch 123/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 4.9002e-04 - val_loss: 0.0059\n",
            "Epoch 124/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 4.8416e-04 - val_loss: 0.0072\n",
            "Epoch 125/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 4.8238e-04 - val_loss: 0.0063\n",
            "Epoch 126/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 4.7431e-04 - val_loss: 0.0069\n",
            "Epoch 127/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 4.6953e-04 - val_loss: 0.0071\n",
            "Epoch 128/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 4.6584e-04 - val_loss: 0.0074\n",
            "Epoch 129/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 4.6316e-04 - val_loss: 0.0073\n",
            "Epoch 130/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 4.5450e-04 - val_loss: 0.0063\n",
            "Epoch 131/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 4.5360e-04 - val_loss: 0.0084\n",
            "Epoch 132/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 4.4806e-04 - val_loss: 0.0072\n",
            "Epoch 133/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 4.4518e-04 - val_loss: 0.0077\n",
            "Epoch 134/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 4.3487e-04 - val_loss: 0.0073\n",
            "Epoch 135/300\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 4.3905e-04 - val_loss: 0.0086\n",
            "Epoch 136/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 4.3151e-04 - val_loss: 0.0080\n",
            "Epoch 137/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 4.2015e-04 - val_loss: 0.0077\n",
            "Epoch 138/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 4.2530e-04 - val_loss: 0.0083\n",
            "Epoch 139/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 4.3158e-04 - val_loss: 0.0088\n",
            "Epoch 140/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 4.1182e-04 - val_loss: 0.0104\n",
            "Epoch 141/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.1515e-04 - val_loss: 0.0094\n",
            "Epoch 142/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.1137e-04 - val_loss: 0.0096\n",
            "Epoch 143/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 4.0091e-04 - val_loss: 0.0098\n",
            "Epoch 144/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.9168e-04 - val_loss: 0.0110\n",
            "Epoch 145/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.9107e-04 - val_loss: 0.0077\n",
            "Epoch 146/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.9274e-04 - val_loss: 0.0112\n",
            "Epoch 147/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.8805e-04 - val_loss: 0.0079\n",
            "Epoch 148/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.9046e-04 - val_loss: 0.0104\n",
            "Epoch 149/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.8112e-04 - val_loss: 0.0092\n",
            "Epoch 150/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.7812e-04 - val_loss: 0.0096\n",
            "Epoch 151/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.7463e-04 - val_loss: 0.0120\n",
            "Epoch 152/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.7800e-04 - val_loss: 0.0106\n",
            "Epoch 153/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.7022e-04 - val_loss: 0.0103\n",
            "Epoch 154/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.6747e-04 - val_loss: 0.0107\n",
            "Epoch 155/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.6867e-04 - val_loss: 0.0115\n",
            "Epoch 156/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 3.6579e-04 - val_loss: 0.0114\n",
            "Epoch 157/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.6205e-04 - val_loss: 0.0113\n",
            "Epoch 158/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 3.5967e-04 - val_loss: 0.0124\n",
            "Epoch 159/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.5775e-04 - val_loss: 0.0112\n",
            "Epoch 160/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.5706e-04 - val_loss: 0.0143\n",
            "Epoch 161/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.7023e-04 - val_loss: 0.0105\n",
            "Epoch 162/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.7935e-04 - val_loss: 0.0152\n",
            "Epoch 163/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.6884e-04 - val_loss: 0.0111\n",
            "Epoch 164/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.6548e-04 - val_loss: 0.0141\n",
            "Epoch 165/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.5880e-04 - val_loss: 0.0128\n",
            "Epoch 166/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 3.4514e-04 - val_loss: 0.0135\n",
            "Epoch 167/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 3.4634e-04 - val_loss: 0.0136\n",
            "Epoch 168/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.4441e-04 - val_loss: 0.0142\n",
            "Epoch 169/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.3992e-04 - val_loss: 0.0142\n",
            "Epoch 170/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.3806e-04 - val_loss: 0.0152\n",
            "Epoch 171/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.3692e-04 - val_loss: 0.0162\n",
            "Epoch 172/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.3602e-04 - val_loss: 0.0163\n",
            "Epoch 173/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 3.3203e-04 - val_loss: 0.0171\n",
            "Epoch 174/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.2961e-04 - val_loss: 0.0188\n",
            "Epoch 175/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 3.3121e-04 - val_loss: 0.0197\n",
            "Epoch 176/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.3175e-04 - val_loss: 0.0187\n",
            "Epoch 177/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.2771e-04 - val_loss: 0.0202\n",
            "Epoch 178/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.2169e-04 - val_loss: 0.0204\n",
            "Epoch 179/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.2162e-04 - val_loss: 0.0226\n",
            "Epoch 180/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.2349e-04 - val_loss: 0.0212\n",
            "Epoch 181/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.2410e-04 - val_loss: 0.0231\n",
            "Epoch 182/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.2032e-04 - val_loss: 0.0245\n",
            "Epoch 183/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.2259e-04 - val_loss: 0.0229\n",
            "Epoch 184/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.1295e-04 - val_loss: 0.0243\n",
            "Epoch 185/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.1327e-04 - val_loss: 0.0243\n",
            "Epoch 186/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.0870e-04 - val_loss: 0.0251\n",
            "Epoch 187/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.0960e-04 - val_loss: 0.0266\n",
            "Epoch 188/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.1389e-04 - val_loss: 0.0256\n",
            "Epoch 189/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.1149e-04 - val_loss: 0.0286\n",
            "Epoch 190/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 3.0569e-04 - val_loss: 0.0256\n",
            "Epoch 191/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.1468e-04 - val_loss: 0.0286\n",
            "Epoch 192/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.0975e-04 - val_loss: 0.0261\n",
            "Epoch 193/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.2000e-04 - val_loss: 0.0255\n",
            "Epoch 194/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.2532e-04 - val_loss: 0.0299\n",
            "Epoch 195/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.3727e-04 - val_loss: 0.0232\n",
            "Epoch 196/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.4972e-04 - val_loss: 0.0276\n",
            "Epoch 197/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.3888e-04 - val_loss: 0.0217\n",
            "Epoch 198/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.0958e-04 - val_loss: 0.0240\n",
            "Epoch 199/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.1458e-04 - val_loss: 0.0215\n",
            "Epoch 200/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.0095e-04 - val_loss: 0.0238\n",
            "Epoch 201/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.0392e-04 - val_loss: 0.0223\n",
            "Epoch 202/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.0665e-04 - val_loss: 0.0247\n",
            "Epoch 203/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.1684e-04 - val_loss: 0.0232\n",
            "Epoch 204/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.1707e-04 - val_loss: 0.0260\n",
            "Epoch 205/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.0775e-04 - val_loss: 0.0238\n",
            "Epoch 206/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.0331e-04 - val_loss: 0.0257\n",
            "Epoch 207/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.9320e-04 - val_loss: 0.0247\n",
            "Epoch 208/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.9436e-04 - val_loss: 0.0262\n",
            "Epoch 209/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.9843e-04 - val_loss: 0.0254\n",
            "Epoch 210/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.9497e-04 - val_loss: 0.0264\n",
            "Epoch 211/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.8884e-04 - val_loss: 0.0260\n",
            "Epoch 212/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.8620e-04 - val_loss: 0.0269\n",
            "Epoch 213/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.9020e-04 - val_loss: 0.0271\n",
            "Epoch 214/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.9140e-04 - val_loss: 0.0282\n",
            "Epoch 215/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.8629e-04 - val_loss: 0.0276\n",
            "Epoch 216/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.8355e-04 - val_loss: 0.0284\n",
            "Epoch 217/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.8544e-04 - val_loss: 0.0296\n",
            "Epoch 218/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.8270e-04 - val_loss: 0.0295\n",
            "Epoch 219/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.7985e-04 - val_loss: 0.0292\n",
            "Epoch 220/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.8204e-04 - val_loss: 0.0304\n",
            "Epoch 221/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.8048e-04 - val_loss: 0.0303\n",
            "Epoch 222/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 2.7665e-04 - val_loss: 0.0313\n",
            "Epoch 223/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.7665e-04 - val_loss: 0.0309\n",
            "Epoch 224/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.8022e-04 - val_loss: 0.0320\n",
            "Epoch 225/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 2.7732e-04 - val_loss: 0.0322\n",
            "Epoch 226/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.7719e-04 - val_loss: 0.0323\n",
            "Epoch 227/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.7754e-04 - val_loss: 0.0335\n",
            "Epoch 228/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.8091e-04 - val_loss: 0.0324\n",
            "Epoch 229/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.7756e-04 - val_loss: 0.0342\n",
            "Epoch 230/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.7267e-04 - val_loss: 0.0336\n",
            "Epoch 231/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.7150e-04 - val_loss: 0.0347\n",
            "Epoch 232/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.7023e-04 - val_loss: 0.0342\n",
            "Epoch 233/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.7621e-04 - val_loss: 0.0348\n",
            "Epoch 234/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 2.7083e-04 - val_loss: 0.0365\n",
            "Epoch 235/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.7213e-04 - val_loss: 0.0354\n",
            "Epoch 236/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.7024e-04 - val_loss: 0.0374\n",
            "Epoch 237/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.7474e-04 - val_loss: 0.0365\n",
            "Epoch 238/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.7109e-04 - val_loss: 0.0366\n",
            "Epoch 239/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6977e-04 - val_loss: 0.0384\n",
            "Epoch 240/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.6733e-04 - val_loss: 0.0387\n",
            "Epoch 241/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.6763e-04 - val_loss: 0.0379\n",
            "Epoch 242/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.8444e-04 - val_loss: 0.0408\n",
            "Epoch 243/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.8707e-04 - val_loss: 0.0348\n",
            "Epoch 244/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 3.1162e-04 - val_loss: 0.0383\n",
            "Epoch 245/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.0561e-04 - val_loss: 0.0330\n",
            "Epoch 246/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.0695e-04 - val_loss: 0.0323\n",
            "Epoch 247/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.8054e-04 - val_loss: 0.0309\n",
            "Epoch 248/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.7564e-04 - val_loss: 0.0320\n",
            "Epoch 249/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.7006e-04 - val_loss: 0.0302\n",
            "Epoch 250/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.8347e-04 - val_loss: 0.0328\n",
            "Epoch 251/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6979e-04 - val_loss: 0.0323\n",
            "Epoch 252/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.7357e-04 - val_loss: 0.0330\n",
            "Epoch 253/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.7200e-04 - val_loss: 0.0327\n",
            "Epoch 254/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.7006e-04 - val_loss: 0.0327\n",
            "Epoch 255/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.6917e-04 - val_loss: 0.0328\n",
            "Epoch 256/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6390e-04 - val_loss: 0.0327\n",
            "Epoch 257/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.6592e-04 - val_loss: 0.0326\n",
            "Epoch 258/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 2.6341e-04 - val_loss: 0.0338\n",
            "Epoch 259/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6134e-04 - val_loss: 0.0333\n",
            "Epoch 260/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.6597e-04 - val_loss: 0.0347\n",
            "Epoch 261/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6462e-04 - val_loss: 0.0358\n",
            "Epoch 262/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.6612e-04 - val_loss: 0.0351\n",
            "Epoch 263/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.6405e-04 - val_loss: 0.0371\n",
            "Epoch 264/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.6553e-04 - val_loss: 0.0354\n",
            "Epoch 265/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6399e-04 - val_loss: 0.0367\n",
            "Epoch 266/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.7241e-04 - val_loss: 0.0356\n",
            "Epoch 267/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6488e-04 - val_loss: 0.0378\n",
            "Epoch 268/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6156e-04 - val_loss: 0.0354\n",
            "Epoch 269/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6936e-04 - val_loss: 0.0373\n",
            "Epoch 270/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6942e-04 - val_loss: 0.0367\n",
            "Epoch 271/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.5855e-04 - val_loss: 0.0370\n",
            "Epoch 272/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6109e-04 - val_loss: 0.0368\n",
            "Epoch 273/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.6142e-04 - val_loss: 0.0392\n",
            "Epoch 274/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6052e-04 - val_loss: 0.0376\n",
            "Epoch 275/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.5839e-04 - val_loss: 0.0382\n",
            "Epoch 276/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 2.6012e-04 - val_loss: 0.0396\n",
            "Epoch 277/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.5788e-04 - val_loss: 0.0381\n",
            "Epoch 278/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.5622e-04 - val_loss: 0.0389\n",
            "Epoch 279/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.5517e-04 - val_loss: 0.0398\n",
            "Epoch 280/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.5683e-04 - val_loss: 0.0386\n",
            "Epoch 281/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6176e-04 - val_loss: 0.0417\n",
            "Epoch 282/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.6354e-04 - val_loss: 0.0387\n",
            "Epoch 283/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.6824e-04 - val_loss: 0.0399\n",
            "Epoch 284/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.6178e-04 - val_loss: 0.0389\n",
            "Epoch 285/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.5707e-04 - val_loss: 0.0387\n",
            "Epoch 286/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.5652e-04 - val_loss: 0.0399\n",
            "Epoch 287/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6107e-04 - val_loss: 0.0392\n",
            "Epoch 288/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.5998e-04 - val_loss: 0.0398\n",
            "Epoch 289/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.5577e-04 - val_loss: 0.0404\n",
            "Epoch 290/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.5522e-04 - val_loss: 0.0408\n",
            "Epoch 291/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.5841e-04 - val_loss: 0.0418\n",
            "Epoch 292/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.5839e-04 - val_loss: 0.0411\n",
            "Epoch 293/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 2.6252e-04 - val_loss: 0.0431\n",
            "Epoch 294/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.5397e-04 - val_loss: 0.0395\n",
            "Epoch 295/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.5761e-04 - val_loss: 0.0419\n",
            "Epoch 296/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.5578e-04 - val_loss: 0.0406\n",
            "Epoch 297/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.5729e-04 - val_loss: 0.0403\n",
            "Epoch 298/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.5709e-04 - val_loss: 0.0425\n",
            "Epoch 299/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.5307e-04 - val_loss: 0.0409\n",
            "Epoch 300/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.5385e-04 - val_loss: 0.0411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 과정 시각화\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(loc=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "c5hNMG7IQXu5",
        "outputId": "ee27d301-c2f8-4799-f939-b3ee4fa64ef4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict=model.predict(X_train)\n",
        "test_predict=model.predict(X_test)\n",
        "\n",
        "X_train.shape, X_test.shape, train_predict.shape, test_predict.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BowcRJmnAVLF",
        "outputId": "10929c5e-ee89-497c-8f09-1bd3d6cca54f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 3ms/step\n",
            "27/27 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1310, 60, 5), (852, 60, 5), (1310, 8), (852, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onedf = maindf[['종가']]\n",
        "onedf['종가'] = onedf['종가'].str.replace(',', '').astype(float)\n",
        "# 데이터 정규화\n",
        "scalerone = MinMaxScaler(feature_range=(0, 1))\n",
        "onedf = scalerone.fit_transform(onedf)\n",
        "onedf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCLfXqO6fEgG",
        "outputId": "7f584c53-38ba-46b9-b6f3-7fb9dceea86a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-96327c31b56a>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  onedf['종가'] = onedf['종가'].str.replace(',', '').astype(float)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2298, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측 결과 역변환 시 shape 문제 해결\n",
        "train_predict = scalerone.inverse_transform(train_predict)\n",
        "test_predict = scalerone.inverse_transform(test_predict)\n",
        "original_ytrain = scalerone.inverse_transform(y_train.reshape(-1,1))\n",
        "original_ytest = scalerone.inverse_transform(y_test.reshape(-1,1))"
      ],
      "metadata": {
        "id": "Ai357VFfe6Dz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data R2 score:\", r2_score(original_ytrain, train_predict))\n",
        "print(\"Test data R2 score:\", r2_score(original_ytest, test_predict))"
      ],
      "metadata": {
        "id": "bkjwUtPQ-Q4S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "47db2546-3093-4e1b-e90e-4d48a8c32c14"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [10480, 1310]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-59560ee74446>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train data R2 score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_ytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test data R2 score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_ytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m     \"\"\"\n\u001b[0;32m--> 911\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    912\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0mkeyword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \"\"\"\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10480, 1310]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"BITCOIN_MODEL_VER2.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUcOEiDo47uI",
        "outputId": "d792184d-47e6-45d2-d5df-03f982efed1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')  # mounts the drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCaB-z4b4rkj",
        "outputId": "59a1769a-c868-4197-9636-8a5e2f5cd7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}