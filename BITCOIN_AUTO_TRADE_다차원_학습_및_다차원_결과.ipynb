{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "15Q5EWfUGI268zyt52t_Oa3tl6b6xOxQX",
      "authorship_tag": "ABX9TyMXPeVz6d0eflzYl42Ytni9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agape1225/BITCOIN-AUTO-TRADE-SERVER/blob/main/BITCOIN_AUTO_TRADE_%EB%8B%A4%EC%B0%A8%EC%9B%90_%ED%95%99%EC%8A%B5_%EB%B0%8F_%EB%8B%A4%EC%B0%A8%EC%9B%90_%EA%B2%B0%EA%B3%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "1I6U3hOJ4hXF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For Evalution we will use these library\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n",
        "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# For model building we will use these library\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "\n",
        "# For PLotting we will use these library\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "maindf = pd.read_csv('BTC_KRW.csv')\n",
        "maindf = maindf.iloc[::-1]\n",
        "\n",
        "# 필요한 열 선택\n",
        "closedf = maindf[['시가', '종가', '고가', '저가', '거래량']]\n",
        "\n",
        "# 데이터 전처리\n",
        "closedf['종가'] = closedf['종가'].str.replace(',', '').astype(float).copy()\n",
        "closedf['시가'] = closedf['시가'].str.replace(',', '').astype(float).copy()\n",
        "closedf['고가'] = closedf['고가'].str.replace(',', '').astype(float).copy()\n",
        "closedf['저가'] = closedf['저가'].str.replace(',', '').astype(float).copy()\n",
        "closedf['거래량'] = closedf['거래량'].str.replace('K', '').astype(float).copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdv6JBh6B2Av",
        "outputId": "e2bae2fc-ac37-4ddd-a882-308eb3b73314"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-174-b52f40b8e3e9>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  closedf['종가'] = closedf['종가'].str.replace(',', '').astype(float).copy()\n",
            "<ipython-input-174-b52f40b8e3e9>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  closedf['시가'] = closedf['시가'].str.replace(',', '').astype(float).copy()\n",
            "<ipython-input-174-b52f40b8e3e9>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  closedf['고가'] = closedf['고가'].str.replace(',', '').astype(float).copy()\n",
            "<ipython-input-174-b52f40b8e3e9>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  closedf['저가'] = closedf['저가'].str.replace(',', '').astype(float).copy()\n",
            "<ipython-input-174-b52f40b8e3e9>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  closedf['거래량'] = closedf['거래량'].str.replace('K', '').astype(float).copy()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 정규화\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "closedf = scaler.fit_transform(closedf)\n",
        "\n",
        "# 데이터 분할\n",
        "training_size = int(len(closedf) * 0.60)\n",
        "test_size = len(closedf) - training_size\n",
        "train_data, test_data = closedf[0:training_size, :], closedf[training_size:len(closedf), :]"
      ],
      "metadata": {
        "id": "cwBa0Yi-CvqD"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시계열 데이터셋 생성 함수\n",
        "def create_dataset(dataset, time_step=1, target_num=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset) - time_step - target_num):\n",
        "        a = dataset[i:(i+time_step), :]\n",
        "        b = dataset[i + time_step : i + time_step + target_num, 1]\n",
        "\n",
        "        dataX.append(a)\n",
        "        dataY.append(b)\n",
        "\n",
        "        #print(a)\n",
        "        #print(b)\n",
        "\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "# 시계열 데이터셋 생성\n",
        "time_step = 60\n",
        "target_num = 8\n",
        "X_train, y_train = create_dataset(train_data, time_step, target_num)\n",
        "X_test, y_test = create_dataset(test_data, time_step, target_num)"
      ],
      "metadata": {
        "id": "TR76FkgWCxc1"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터의 차원을 3차원으로 변경\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2])"
      ],
      "metadata": {
        "id": "aKLNr_l4Fpu0"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM 모델 정의 및 학습\n",
        "model = Sequential()\n",
        "model.add(LSTM(40, input_shape=(X_train.shape[1], X_train.shape[2]), activation=\"tanh\"))\n",
        "model.add(Dense(target_num))\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=300, batch_size=512, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-3XXoZwF6Az",
        "outputId": "f5c2a304-352a-4694-e692-e5fccee7b834"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "3/3 [==============================] - 3s 394ms/step - loss: 0.0234 - val_loss: 0.2320\n",
            "Epoch 2/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0183 - val_loss: 0.1844\n",
            "Epoch 3/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0137 - val_loss: 0.1411\n",
            "Epoch 4/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0103 - val_loss: 0.1012\n",
            "Epoch 5/300\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0076 - val_loss: 0.0676\n",
            "Epoch 6/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0057 - val_loss: 0.0429\n",
            "Epoch 7/300\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0043 - val_loss: 0.0268\n",
            "Epoch 8/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.0171\n",
            "Epoch 9/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.0116\n",
            "Epoch 10/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.0093\n",
            "Epoch 11/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.0119\n",
            "Epoch 12/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0155\n",
            "Epoch 13/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0014 - val_loss: 0.0142\n",
            "Epoch 14/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0013 - val_loss: 0.0119\n",
            "Epoch 15/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.0115\n",
            "Epoch 16/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.0118\n",
            "Epoch 17/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 9.3937e-04 - val_loss: 0.0109\n",
            "Epoch 18/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 8.7414e-04 - val_loss: 0.0082\n",
            "Epoch 19/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 8.2637e-04 - val_loss: 0.0066\n",
            "Epoch 20/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.8813e-04 - val_loss: 0.0067\n",
            "Epoch 21/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.6488e-04 - val_loss: 0.0072\n",
            "Epoch 22/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 7.5127e-04 - val_loss: 0.0072\n",
            "Epoch 23/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 7.3531e-04 - val_loss: 0.0071\n",
            "Epoch 24/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 7.2272e-04 - val_loss: 0.0068\n",
            "Epoch 25/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 7.1524e-04 - val_loss: 0.0074\n",
            "Epoch 26/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 7.0605e-04 - val_loss: 0.0080\n",
            "Epoch 27/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 7.0448e-04 - val_loss: 0.0076\n",
            "Epoch 28/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.9628e-04 - val_loss: 0.0071\n",
            "Epoch 29/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.9030e-04 - val_loss: 0.0067\n",
            "Epoch 30/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 6.8457e-04 - val_loss: 0.0060\n",
            "Epoch 31/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 6.8072e-04 - val_loss: 0.0056\n",
            "Epoch 32/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 6.7699e-04 - val_loss: 0.0057\n",
            "Epoch 33/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 6.7255e-04 - val_loss: 0.0062\n",
            "Epoch 34/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 6.6787e-04 - val_loss: 0.0056\n",
            "Epoch 35/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 6.6601e-04 - val_loss: 0.0049\n",
            "Epoch 36/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.6057e-04 - val_loss: 0.0055\n",
            "Epoch 37/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.5442e-04 - val_loss: 0.0060\n",
            "Epoch 38/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.5503e-04 - val_loss: 0.0058\n",
            "Epoch 39/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.5125e-04 - val_loss: 0.0055\n",
            "Epoch 40/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 6.4667e-04 - val_loss: 0.0054\n",
            "Epoch 41/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.4385e-04 - val_loss: 0.0052\n",
            "Epoch 42/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 6.4016e-04 - val_loss: 0.0052\n",
            "Epoch 43/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 6.3643e-04 - val_loss: 0.0050\n",
            "Epoch 44/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 6.3362e-04 - val_loss: 0.0048\n",
            "Epoch 45/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.3254e-04 - val_loss: 0.0047\n",
            "Epoch 46/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.2772e-04 - val_loss: 0.0049\n",
            "Epoch 47/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 6.2538e-04 - val_loss: 0.0048\n",
            "Epoch 48/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 6.2325e-04 - val_loss: 0.0046\n",
            "Epoch 49/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 6.1902e-04 - val_loss: 0.0049\n",
            "Epoch 50/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 6.1728e-04 - val_loss: 0.0046\n",
            "Epoch 51/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 6.1373e-04 - val_loss: 0.0046\n",
            "Epoch 52/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 6.0917e-04 - val_loss: 0.0043\n",
            "Epoch 53/300\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 6.0798e-04 - val_loss: 0.0039\n",
            "Epoch 54/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 6.0686e-04 - val_loss: 0.0042\n",
            "Epoch 55/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 6.0383e-04 - val_loss: 0.0045\n",
            "Epoch 56/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 5.9783e-04 - val_loss: 0.0040\n",
            "Epoch 57/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 5.9653e-04 - val_loss: 0.0037\n",
            "Epoch 58/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 5.9446e-04 - val_loss: 0.0040\n",
            "Epoch 59/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 5.9498e-04 - val_loss: 0.0045\n",
            "Epoch 60/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 5.8917e-04 - val_loss: 0.0038\n",
            "Epoch 61/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 5.8799e-04 - val_loss: 0.0036\n",
            "Epoch 62/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 5.8254e-04 - val_loss: 0.0043\n",
            "Epoch 63/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 5.8007e-04 - val_loss: 0.0041\n",
            "Epoch 64/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 5.7531e-04 - val_loss: 0.0037\n",
            "Epoch 65/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 5.7340e-04 - val_loss: 0.0037\n",
            "Epoch 66/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 5.7391e-04 - val_loss: 0.0041\n",
            "Epoch 67/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 5.6525e-04 - val_loss: 0.0035\n",
            "Epoch 68/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 5.6333e-04 - val_loss: 0.0034\n",
            "Epoch 69/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 5.6104e-04 - val_loss: 0.0036\n",
            "Epoch 70/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 5.5988e-04 - val_loss: 0.0036\n",
            "Epoch 71/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 5.5530e-04 - val_loss: 0.0036\n",
            "Epoch 72/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 5.5272e-04 - val_loss: 0.0033\n",
            "Epoch 73/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 5.5086e-04 - val_loss: 0.0034\n",
            "Epoch 74/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 5.4582e-04 - val_loss: 0.0036\n",
            "Epoch 75/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 5.4358e-04 - val_loss: 0.0037\n",
            "Epoch 76/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 5.4274e-04 - val_loss: 0.0033\n",
            "Epoch 77/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 5.3726e-04 - val_loss: 0.0035\n",
            "Epoch 78/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 5.3472e-04 - val_loss: 0.0037\n",
            "Epoch 79/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 5.2966e-04 - val_loss: 0.0033\n",
            "Epoch 80/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 5.2699e-04 - val_loss: 0.0034\n",
            "Epoch 81/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 5.2388e-04 - val_loss: 0.0036\n",
            "Epoch 82/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 5.2299e-04 - val_loss: 0.0036\n",
            "Epoch 83/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 5.1819e-04 - val_loss: 0.0033\n",
            "Epoch 84/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 5.1578e-04 - val_loss: 0.0033\n",
            "Epoch 85/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 5.1078e-04 - val_loss: 0.0034\n",
            "Epoch 86/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 5.0902e-04 - val_loss: 0.0034\n",
            "Epoch 87/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 5.0711e-04 - val_loss: 0.0032\n",
            "Epoch 88/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 5.0292e-04 - val_loss: 0.0035\n",
            "Epoch 89/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.9970e-04 - val_loss: 0.0034\n",
            "Epoch 90/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 4.9343e-04 - val_loss: 0.0032\n",
            "Epoch 91/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.9438e-04 - val_loss: 0.0033\n",
            "Epoch 92/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 4.8894e-04 - val_loss: 0.0036\n",
            "Epoch 93/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.8585e-04 - val_loss: 0.0034\n",
            "Epoch 94/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 4.8136e-04 - val_loss: 0.0034\n",
            "Epoch 95/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.7872e-04 - val_loss: 0.0034\n",
            "Epoch 96/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.7723e-04 - val_loss: 0.0034\n",
            "Epoch 97/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.7156e-04 - val_loss: 0.0035\n",
            "Epoch 98/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.6925e-04 - val_loss: 0.0035\n",
            "Epoch 99/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.6529e-04 - val_loss: 0.0034\n",
            "Epoch 100/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.6319e-04 - val_loss: 0.0035\n",
            "Epoch 101/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.5917e-04 - val_loss: 0.0036\n",
            "Epoch 102/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 4.6733e-04 - val_loss: 0.0037\n",
            "Epoch 103/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 4.5485e-04 - val_loss: 0.0035\n",
            "Epoch 104/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 4.5268e-04 - val_loss: 0.0039\n",
            "Epoch 105/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 4.5224e-04 - val_loss: 0.0040\n",
            "Epoch 106/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.4701e-04 - val_loss: 0.0036\n",
            "Epoch 107/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.4220e-04 - val_loss: 0.0040\n",
            "Epoch 108/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 4.4297e-04 - val_loss: 0.0040\n",
            "Epoch 109/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 4.4069e-04 - val_loss: 0.0038\n",
            "Epoch 110/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 4.3715e-04 - val_loss: 0.0044\n",
            "Epoch 111/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 4.3215e-04 - val_loss: 0.0038\n",
            "Epoch 112/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 4.3091e-04 - val_loss: 0.0039\n",
            "Epoch 113/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 4.2488e-04 - val_loss: 0.0050\n",
            "Epoch 114/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 4.3832e-04 - val_loss: 0.0046\n",
            "Epoch 115/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 4.2153e-04 - val_loss: 0.0042\n",
            "Epoch 116/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 4.2381e-04 - val_loss: 0.0052\n",
            "Epoch 117/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 4.2921e-04 - val_loss: 0.0046\n",
            "Epoch 118/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 4.2337e-04 - val_loss: 0.0045\n",
            "Epoch 119/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 4.1587e-04 - val_loss: 0.0054\n",
            "Epoch 120/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 4.0910e-04 - val_loss: 0.0044\n",
            "Epoch 121/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 4.1547e-04 - val_loss: 0.0051\n",
            "Epoch 122/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 4.0800e-04 - val_loss: 0.0055\n",
            "Epoch 123/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 4.0747e-04 - val_loss: 0.0049\n",
            "Epoch 124/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 4.0641e-04 - val_loss: 0.0063\n",
            "Epoch 125/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 4.0047e-04 - val_loss: 0.0050\n",
            "Epoch 126/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 3.9670e-04 - val_loss: 0.0060\n",
            "Epoch 127/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 4.0004e-04 - val_loss: 0.0058\n",
            "Epoch 128/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 3.9272e-04 - val_loss: 0.0057\n",
            "Epoch 129/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.9259e-04 - val_loss: 0.0064\n",
            "Epoch 130/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 3.9127e-04 - val_loss: 0.0063\n",
            "Epoch 131/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 3.9095e-04 - val_loss: 0.0057\n",
            "Epoch 132/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 3.8652e-04 - val_loss: 0.0058\n",
            "Epoch 133/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 3.8416e-04 - val_loss: 0.0070\n",
            "Epoch 134/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 3.8591e-04 - val_loss: 0.0056\n",
            "Epoch 135/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.8988e-04 - val_loss: 0.0068\n",
            "Epoch 136/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.8964e-04 - val_loss: 0.0069\n",
            "Epoch 137/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.7611e-04 - val_loss: 0.0063\n",
            "Epoch 138/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 3.7334e-04 - val_loss: 0.0081\n",
            "Epoch 139/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 3.7716e-04 - val_loss: 0.0064\n",
            "Epoch 140/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 3.7338e-04 - val_loss: 0.0072\n",
            "Epoch 141/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.6843e-04 - val_loss: 0.0072\n",
            "Epoch 142/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.6848e-04 - val_loss: 0.0085\n",
            "Epoch 143/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.6659e-04 - val_loss: 0.0073\n",
            "Epoch 144/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 3.6826e-04 - val_loss: 0.0084\n",
            "Epoch 145/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.6301e-04 - val_loss: 0.0083\n",
            "Epoch 146/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.6093e-04 - val_loss: 0.0084\n",
            "Epoch 147/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.6084e-04 - val_loss: 0.0083\n",
            "Epoch 148/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 3.5878e-04 - val_loss: 0.0083\n",
            "Epoch 149/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.6259e-04 - val_loss: 0.0096\n",
            "Epoch 150/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 3.6022e-04 - val_loss: 0.0077\n",
            "Epoch 151/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 3.5415e-04 - val_loss: 0.0082\n",
            "Epoch 152/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.5195e-04 - val_loss: 0.0089\n",
            "Epoch 153/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.5079e-04 - val_loss: 0.0093\n",
            "Epoch 154/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.4938e-04 - val_loss: 0.0099\n",
            "Epoch 155/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.4959e-04 - val_loss: 0.0093\n",
            "Epoch 156/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 3.4866e-04 - val_loss: 0.0090\n",
            "Epoch 157/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.4700e-04 - val_loss: 0.0087\n",
            "Epoch 158/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.5523e-04 - val_loss: 0.0128\n",
            "Epoch 159/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.5840e-04 - val_loss: 0.0085\n",
            "Epoch 160/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.4989e-04 - val_loss: 0.0104\n",
            "Epoch 161/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.4198e-04 - val_loss: 0.0098\n",
            "Epoch 162/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.3900e-04 - val_loss: 0.0104\n",
            "Epoch 163/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 3.4550e-04 - val_loss: 0.0096\n",
            "Epoch 164/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 3.5223e-04 - val_loss: 0.0114\n",
            "Epoch 165/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 3.5199e-04 - val_loss: 0.0104\n",
            "Epoch 166/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.4644e-04 - val_loss: 0.0101\n",
            "Epoch 167/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 3.3766e-04 - val_loss: 0.0119\n",
            "Epoch 168/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 3.3405e-04 - val_loss: 0.0096\n",
            "Epoch 169/300\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 3.3690e-04 - val_loss: 0.0111\n",
            "Epoch 170/300\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 3.3362e-04 - val_loss: 0.0113\n",
            "Epoch 171/300\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 3.2908e-04 - val_loss: 0.0120\n",
            "Epoch 172/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 3.2885e-04 - val_loss: 0.0113\n",
            "Epoch 173/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 3.2979e-04 - val_loss: 0.0126\n",
            "Epoch 174/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 3.2674e-04 - val_loss: 0.0125\n",
            "Epoch 175/300\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 3.2903e-04 - val_loss: 0.0131\n",
            "Epoch 176/300\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 3.2713e-04 - val_loss: 0.0125\n",
            "Epoch 177/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 3.2531e-04 - val_loss: 0.0124\n",
            "Epoch 178/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 3.2491e-04 - val_loss: 0.0131\n",
            "Epoch 179/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 3.2495e-04 - val_loss: 0.0128\n",
            "Epoch 180/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 3.2807e-04 - val_loss: 0.0127\n",
            "Epoch 181/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 3.3153e-04 - val_loss: 0.0141\n",
            "Epoch 182/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 3.3186e-04 - val_loss: 0.0132\n",
            "Epoch 183/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 3.3122e-04 - val_loss: 0.0141\n",
            "Epoch 184/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 3.2141e-04 - val_loss: 0.0156\n",
            "Epoch 185/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 3.1843e-04 - val_loss: 0.0127\n",
            "Epoch 186/300\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 3.2383e-04 - val_loss: 0.0155\n",
            "Epoch 187/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 3.2050e-04 - val_loss: 0.0132\n",
            "Epoch 188/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 3.2221e-04 - val_loss: 0.0159\n",
            "Epoch 189/300\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 3.1690e-04 - val_loss: 0.0145\n",
            "Epoch 190/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 3.1405e-04 - val_loss: 0.0164\n",
            "Epoch 191/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 3.1386e-04 - val_loss: 0.0161\n",
            "Epoch 192/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 3.0960e-04 - val_loss: 0.0157\n",
            "Epoch 193/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.1091e-04 - val_loss: 0.0160\n",
            "Epoch 194/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 3.2128e-04 - val_loss: 0.0156\n",
            "Epoch 195/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 3.1741e-04 - val_loss: 0.0181\n",
            "Epoch 196/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 3.1277e-04 - val_loss: 0.0166\n",
            "Epoch 197/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 3.0955e-04 - val_loss: 0.0180\n",
            "Epoch 198/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 3.0985e-04 - val_loss: 0.0180\n",
            "Epoch 199/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.0788e-04 - val_loss: 0.0185\n",
            "Epoch 200/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 3.0450e-04 - val_loss: 0.0190\n",
            "Epoch 201/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 3.0483e-04 - val_loss: 0.0202\n",
            "Epoch 202/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.0270e-04 - val_loss: 0.0203\n",
            "Epoch 203/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 3.0416e-04 - val_loss: 0.0198\n",
            "Epoch 204/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.0428e-04 - val_loss: 0.0192\n",
            "Epoch 205/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.0588e-04 - val_loss: 0.0212\n",
            "Epoch 206/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 3.0703e-04 - val_loss: 0.0195\n",
            "Epoch 207/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 3.0045e-04 - val_loss: 0.0228\n",
            "Epoch 208/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.0098e-04 - val_loss: 0.0216\n",
            "Epoch 209/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.9485e-04 - val_loss: 0.0235\n",
            "Epoch 210/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.9830e-04 - val_loss: 0.0214\n",
            "Epoch 211/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.0111e-04 - val_loss: 0.0234\n",
            "Epoch 212/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.9453e-04 - val_loss: 0.0218\n",
            "Epoch 213/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 3.0088e-04 - val_loss: 0.0238\n",
            "Epoch 214/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.9597e-04 - val_loss: 0.0232\n",
            "Epoch 215/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 2.9405e-04 - val_loss: 0.0237\n",
            "Epoch 216/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.9427e-04 - val_loss: 0.0253\n",
            "Epoch 217/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.9818e-04 - val_loss: 0.0240\n",
            "Epoch 218/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.9169e-04 - val_loss: 0.0260\n",
            "Epoch 219/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.9357e-04 - val_loss: 0.0252\n",
            "Epoch 220/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 2.9304e-04 - val_loss: 0.0253\n",
            "Epoch 221/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.9444e-04 - val_loss: 0.0290\n",
            "Epoch 222/300\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 2.9123e-04 - val_loss: 0.0236\n",
            "Epoch 223/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 3.1728e-04 - val_loss: 0.0284\n",
            "Epoch 224/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 3.1031e-04 - val_loss: 0.0219\n",
            "Epoch 225/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 2.9666e-04 - val_loss: 0.0282\n",
            "Epoch 226/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 3.2778e-04 - val_loss: 0.0213\n",
            "Epoch 227/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.9709e-04 - val_loss: 0.0246\n",
            "Epoch 228/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 2.9479e-04 - val_loss: 0.0229\n",
            "Epoch 229/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 2.9199e-04 - val_loss: 0.0251\n",
            "Epoch 230/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 2.8316e-04 - val_loss: 0.0251\n",
            "Epoch 231/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 2.8703e-04 - val_loss: 0.0262\n",
            "Epoch 232/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 2.8708e-04 - val_loss: 0.0279\n",
            "Epoch 233/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.9068e-04 - val_loss: 0.0263\n",
            "Epoch 234/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 2.8677e-04 - val_loss: 0.0285\n",
            "Epoch 235/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 2.9113e-04 - val_loss: 0.0268\n",
            "Epoch 236/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 2.9192e-04 - val_loss: 0.0289\n",
            "Epoch 237/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 2.9107e-04 - val_loss: 0.0268\n",
            "Epoch 238/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.9764e-04 - val_loss: 0.0275\n",
            "Epoch 239/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 2.9656e-04 - val_loss: 0.0257\n",
            "Epoch 240/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 2.8880e-04 - val_loss: 0.0264\n",
            "Epoch 241/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 2.9179e-04 - val_loss: 0.0263\n",
            "Epoch 242/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 2.8643e-04 - val_loss: 0.0271\n",
            "Epoch 243/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 2.9299e-04 - val_loss: 0.0262\n",
            "Epoch 244/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 3.0112e-04 - val_loss: 0.0258\n",
            "Epoch 245/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.1869e-04 - val_loss: 0.0250\n",
            "Epoch 246/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.0154e-04 - val_loss: 0.0237\n",
            "Epoch 247/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 2.8773e-04 - val_loss: 0.0266\n",
            "Epoch 248/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.8761e-04 - val_loss: 0.0243\n",
            "Epoch 249/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.8035e-04 - val_loss: 0.0265\n",
            "Epoch 250/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.8418e-04 - val_loss: 0.0258\n",
            "Epoch 251/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.7571e-04 - val_loss: 0.0271\n",
            "Epoch 252/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.8313e-04 - val_loss: 0.0280\n",
            "Epoch 253/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.8503e-04 - val_loss: 0.0275\n",
            "Epoch 254/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.8097e-04 - val_loss: 0.0295\n",
            "Epoch 255/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 2.8163e-04 - val_loss: 0.0272\n",
            "Epoch 256/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 2.8356e-04 - val_loss: 0.0289\n",
            "Epoch 257/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.7059e-04 - val_loss: 0.0275\n",
            "Epoch 258/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.7580e-04 - val_loss: 0.0283\n",
            "Epoch 259/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 2.6956e-04 - val_loss: 0.0286\n",
            "Epoch 260/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 2.6706e-04 - val_loss: 0.0286\n",
            "Epoch 261/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 2.6726e-04 - val_loss: 0.0299\n",
            "Epoch 262/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.6460e-04 - val_loss: 0.0294\n",
            "Epoch 263/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.6185e-04 - val_loss: 0.0312\n",
            "Epoch 264/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.6184e-04 - val_loss: 0.0310\n",
            "Epoch 265/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.6237e-04 - val_loss: 0.0320\n",
            "Epoch 266/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.6065e-04 - val_loss: 0.0323\n",
            "Epoch 267/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.5939e-04 - val_loss: 0.0327\n",
            "Epoch 268/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.5983e-04 - val_loss: 0.0332\n",
            "Epoch 269/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.5756e-04 - val_loss: 0.0332\n",
            "Epoch 270/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.5807e-04 - val_loss: 0.0338\n",
            "Epoch 271/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.6019e-04 - val_loss: 0.0346\n",
            "Epoch 272/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 2.5882e-04 - val_loss: 0.0343\n",
            "Epoch 273/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.5610e-04 - val_loss: 0.0351\n",
            "Epoch 274/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.5564e-04 - val_loss: 0.0360\n",
            "Epoch 275/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.5429e-04 - val_loss: 0.0360\n",
            "Epoch 276/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 2.5474e-04 - val_loss: 0.0373\n",
            "Epoch 277/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.5296e-04 - val_loss: 0.0370\n",
            "Epoch 278/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.5517e-04 - val_loss: 0.0379\n",
            "Epoch 279/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.5564e-04 - val_loss: 0.0369\n",
            "Epoch 280/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 2.5770e-04 - val_loss: 0.0388\n",
            "Epoch 281/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 2.5903e-04 - val_loss: 0.0373\n",
            "Epoch 282/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 2.5932e-04 - val_loss: 0.0391\n",
            "Epoch 283/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 2.5489e-04 - val_loss: 0.0373\n",
            "Epoch 284/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.5299e-04 - val_loss: 0.0380\n",
            "Epoch 285/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.4733e-04 - val_loss: 0.0388\n",
            "Epoch 286/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 2.4919e-04 - val_loss: 0.0392\n",
            "Epoch 287/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 2.4742e-04 - val_loss: 0.0399\n",
            "Epoch 288/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 2.4861e-04 - val_loss: 0.0408\n",
            "Epoch 289/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 2.4642e-04 - val_loss: 0.0416\n",
            "Epoch 290/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 2.5025e-04 - val_loss: 0.0410\n",
            "Epoch 291/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 2.5058e-04 - val_loss: 0.0416\n",
            "Epoch 292/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 2.4438e-04 - val_loss: 0.0417\n",
            "Epoch 293/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 2.4792e-04 - val_loss: 0.0428\n",
            "Epoch 294/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 2.4466e-04 - val_loss: 0.0440\n",
            "Epoch 295/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 2.4381e-04 - val_loss: 0.0442\n",
            "Epoch 296/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 2.4197e-04 - val_loss: 0.0443\n",
            "Epoch 297/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 2.4391e-04 - val_loss: 0.0444\n",
            "Epoch 298/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.4087e-04 - val_loss: 0.0456\n",
            "Epoch 299/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 2.4417e-04 - val_loss: 0.0462\n",
            "Epoch 300/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 2.4271e-04 - val_loss: 0.0456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 과정 시각화\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(loc=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "c5hNMG7IQXu5",
        "outputId": "70a0f2d6-4ad5-4872-f4d1-695912e156b0"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict=model.predict(X_train)\n",
        "test_predict=model.predict(X_test)\n",
        "#print(X_train.shape)\n",
        "X_train.shape, X_test.shape, train_predict.shape, test_predict.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BowcRJmnAVLF",
        "outputId": "770f11f5-37ba-44e7-92d7-026b4ff15571"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 1s 3ms/step\n",
            "27/27 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1303, 60, 5), (845, 60, 5), (1303, 15), (845, 15))"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict = scaler.inverse_transform(train_predict)\n",
        "test_predict = scaler.inverse_transform(test_predict)\n",
        "original_ytrain = scaler.inverse_transform(y_train.reshape(-1,1))\n",
        "original_ytest = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "#print(test_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "24lGT_pn-QIb",
        "outputId": "e0437dc7-29af-43a9-fe84-574b020af98f"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (1303,15) (5,) (1303,15) ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-7b69c80bc8b9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moriginal_ytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moriginal_ytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(test_predict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    539\u001b[0m         )\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1303,15) (5,) (1303,15) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data R2 score:\", r2_score(original_ytrain, train_predict))\n",
        "print(\"Test data R2 score:\", r2_score(original_ytest, test_predict))"
      ],
      "metadata": {
        "id": "bkjwUtPQ-Q4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"BITCOIN_MODEL_VER2.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUcOEiDo47uI",
        "outputId": "d792184d-47e6-45d2-d5df-03f982efed1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')  # mounts the drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCaB-z4b4rkj",
        "outputId": "59a1769a-c868-4197-9636-8a5e2f5cd7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}