{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "15Q5EWfUGI268zyt52t_Oa3tl6b6xOxQX",
      "authorship_tag": "ABX9TyOOm1pr71gmkCpGdIejcYhT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agape1225/BITCOIN-AUTO-TRADE-SERVER/blob/main/BITCOIN_AUTO_TRADE_%EB%8B%A4%EC%B0%A8%EC%9B%90_%ED%95%99%EC%8A%B5_%EB%B0%8F_%EB%8B%A4%EC%B0%A8%EC%9B%90_%EA%B2%B0%EA%B3%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "1I6U3hOJ4hXF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For Evalution we will use these library\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n",
        "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# For model building we will use these library\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "\n",
        "# For PLotting we will use these library\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "maindf = pd.read_csv('BTC_KRW.csv')\n",
        "maindf = maindf.iloc[::-1]\n",
        "\n",
        "# 필요한 열 선택\n",
        "closedf = maindf[['시가', '종가', '고가', '저가', '거래량']]\n",
        "\n",
        "# 데이터 전처리\n",
        "closedf['종가'] = closedf['종가'].str.replace(',', '').astype(float)\n",
        "closedf['시가'] = closedf['시가'].str.replace(',', '').astype(float)\n",
        "closedf['고가'] = closedf['고가'].str.replace(',', '').astype(float)\n",
        "closedf['저가'] = closedf['저가'].str.replace(',', '').astype(float)\n",
        "closedf['거래량'] = closedf['거래량'].str.replace('K', '').astype(float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdv6JBh6B2Av",
        "outputId": "ebbe5729-babf-48a8-cd70-f00c54314beb"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-116-4078aebaaefa>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  closedf['종가'] = closedf['종가'].str.replace(',', '').astype(float)\n",
            "<ipython-input-116-4078aebaaefa>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  closedf['시가'] = closedf['시가'].str.replace(',', '').astype(float)\n",
            "<ipython-input-116-4078aebaaefa>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  closedf['고가'] = closedf['고가'].str.replace(',', '').astype(float)\n",
            "<ipython-input-116-4078aebaaefa>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  closedf['저가'] = closedf['저가'].str.replace(',', '').astype(float)\n",
            "<ipython-input-116-4078aebaaefa>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  closedf['거래량'] = closedf['거래량'].str.replace('K', '').astype(float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 정규화\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "closedf = scaler.fit_transform(closedf)\n",
        "\n",
        "# 데이터 분할\n",
        "training_size = int(len(closedf) * 0.60)\n",
        "test_size = len(closedf) - training_size\n",
        "train_data, test_data = closedf[0:training_size, :], closedf[training_size:len(closedf), :]"
      ],
      "metadata": {
        "id": "cwBa0Yi-CvqD"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시계열 데이터셋 생성 함수\n",
        "def create_dataset(dataset, time_step=1, target_num=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset) - time_step - target_num):\n",
        "        a = dataset[i:(i+time_step), :]\n",
        "        b = dataset[i + time_step : i + time_step + target_num, 1]\n",
        "\n",
        "        dataX.append(a)\n",
        "        dataY.append(b)\n",
        "\n",
        "        #print(a)\n",
        "        #print(b)\n",
        "\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "# 시계열 데이터셋 생성\n",
        "time_step = 60\n",
        "target_num = 15\n",
        "X_train, y_train = create_dataset(train_data, time_step, target_num)\n",
        "X_test, y_test = create_dataset(test_data, time_step, target_num)"
      ],
      "metadata": {
        "id": "TR76FkgWCxc1"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터의 차원을 3차원으로 변경\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2])"
      ],
      "metadata": {
        "id": "aKLNr_l4Fpu0"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM 모델 정의 및 학습\n",
        "model = Sequential()\n",
        "model.add(LSTM(20, input_shape=(X_train.shape[1], X_train.shape[2]), activation=\"tanh\"))\n",
        "model.add(Dense(target_num))\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=300, batch_size=512, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-3XXoZwF6Az",
        "outputId": "bb7ef06c-b163-4115-a760-a0087e336dd4"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "3/3 [==============================] - 3s 386ms/step - loss: 0.0255 - val_loss: 0.2721\n",
            "Epoch 2/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0221 - val_loss: 0.2425\n",
            "Epoch 3/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0191 - val_loss: 0.2159\n",
            "Epoch 4/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0166 - val_loss: 0.1917\n",
            "Epoch 5/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0144 - val_loss: 0.1697\n",
            "Epoch 6/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0125 - val_loss: 0.1496\n",
            "Epoch 7/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0109 - val_loss: 0.1313\n",
            "Epoch 8/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0095 - val_loss: 0.1145\n",
            "Epoch 9/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0083 - val_loss: 0.0993\n",
            "Epoch 10/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0856\n",
            "Epoch 11/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0064 - val_loss: 0.0732\n",
            "Epoch 12/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0621\n",
            "Epoch 13/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0047 - val_loss: 0.0519\n",
            "Epoch 14/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0040 - val_loss: 0.0429\n",
            "Epoch 15/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0035 - val_loss: 0.0351\n",
            "Epoch 16/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0030 - val_loss: 0.0289\n",
            "Epoch 17/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0026 - val_loss: 0.0245\n",
            "Epoch 18/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0023 - val_loss: 0.0214\n",
            "Epoch 19/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0021 - val_loss: 0.0191\n",
            "Epoch 20/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0020 - val_loss: 0.0174\n",
            "Epoch 21/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0019 - val_loss: 0.0160\n",
            "Epoch 22/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0018 - val_loss: 0.0150\n",
            "Epoch 23/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0017 - val_loss: 0.0141\n",
            "Epoch 24/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0016 - val_loss: 0.0133\n",
            "Epoch 25/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0015 - val_loss: 0.0122\n",
            "Epoch 26/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0015 - val_loss: 0.0113\n",
            "Epoch 27/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0014 - val_loss: 0.0107\n",
            "Epoch 28/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0014 - val_loss: 0.0108\n",
            "Epoch 29/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0014 - val_loss: 0.0109\n",
            "Epoch 30/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0013 - val_loss: 0.0108\n",
            "Epoch 31/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0013 - val_loss: 0.0103\n",
            "Epoch 32/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0013 - val_loss: 0.0101\n",
            "Epoch 33/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0012 - val_loss: 0.0102\n",
            "Epoch 34/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0012 - val_loss: 0.0104\n",
            "Epoch 35/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0012 - val_loss: 0.0107\n",
            "Epoch 36/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0012 - val_loss: 0.0104\n",
            "Epoch 37/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0012 - val_loss: 0.0098\n",
            "Epoch 38/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0012 - val_loss: 0.0095\n",
            "Epoch 39/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0011 - val_loss: 0.0100\n",
            "Epoch 40/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0011 - val_loss: 0.0101\n",
            "Epoch 41/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0011 - val_loss: 0.0106\n",
            "Epoch 42/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0011 - val_loss: 0.0101\n",
            "Epoch 43/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0011 - val_loss: 0.0093\n",
            "Epoch 44/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0011 - val_loss: 0.0097\n",
            "Epoch 45/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0011 - val_loss: 0.0102\n",
            "Epoch 46/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0011 - val_loss: 0.0103\n",
            "Epoch 47/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0011 - val_loss: 0.0097\n",
            "Epoch 48/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0011 - val_loss: 0.0094\n",
            "Epoch 49/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0011 - val_loss: 0.0093\n",
            "Epoch 50/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0010 - val_loss: 0.0094\n",
            "Epoch 51/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0010 - val_loss: 0.0101\n",
            "Epoch 52/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0010 - val_loss: 0.0099\n",
            "Epoch 53/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0010 - val_loss: 0.0096\n",
            "Epoch 54/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0010 - val_loss: 0.0093\n",
            "Epoch 55/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0010 - val_loss: 0.0091\n",
            "Epoch 56/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0010 - val_loss: 0.0093\n",
            "Epoch 57/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0010 - val_loss: 0.0098\n",
            "Epoch 58/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0010 - val_loss: 0.0098\n",
            "Epoch 59/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0010 - val_loss: 0.0099\n",
            "Epoch 60/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0010 - val_loss: 0.0093\n",
            "Epoch 61/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0010 - val_loss: 0.0091\n",
            "Epoch 62/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0010 - val_loss: 0.0091\n",
            "Epoch 63/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0010 - val_loss: 0.0091\n",
            "Epoch 64/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 9.9658e-04 - val_loss: 0.0094\n",
            "Epoch 65/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 9.9368e-04 - val_loss: 0.0098\n",
            "Epoch 66/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 9.9264e-04 - val_loss: 0.0097\n",
            "Epoch 67/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 9.8917e-04 - val_loss: 0.0095\n",
            "Epoch 68/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 9.8711e-04 - val_loss: 0.0094\n",
            "Epoch 69/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 9.8396e-04 - val_loss: 0.0097\n",
            "Epoch 70/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 9.8124e-04 - val_loss: 0.0096\n",
            "Epoch 71/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 9.7983e-04 - val_loss: 0.0094\n",
            "Epoch 72/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 9.7862e-04 - val_loss: 0.0088\n",
            "Epoch 73/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 9.7609e-04 - val_loss: 0.0090\n",
            "Epoch 74/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.7382e-04 - val_loss: 0.0093\n",
            "Epoch 75/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 9.7068e-04 - val_loss: 0.0091\n",
            "Epoch 76/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 9.6662e-04 - val_loss: 0.0092\n",
            "Epoch 77/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.6517e-04 - val_loss: 0.0094\n",
            "Epoch 78/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.6349e-04 - val_loss: 0.0095\n",
            "Epoch 79/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 9.6824e-04 - val_loss: 0.0099\n",
            "Epoch 80/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 9.5994e-04 - val_loss: 0.0091\n",
            "Epoch 81/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 9.5761e-04 - val_loss: 0.0089\n",
            "Epoch 82/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 9.5754e-04 - val_loss: 0.0090\n",
            "Epoch 83/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.5738e-04 - val_loss: 0.0088\n",
            "Epoch 84/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 9.5138e-04 - val_loss: 0.0092\n",
            "Epoch 85/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 9.5039e-04 - val_loss: 0.0093\n",
            "Epoch 86/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 9.4959e-04 - val_loss: 0.0093\n",
            "Epoch 87/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 9.4653e-04 - val_loss: 0.0095\n",
            "Epoch 88/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 9.4331e-04 - val_loss: 0.0092\n",
            "Epoch 89/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.4279e-04 - val_loss: 0.0090\n",
            "Epoch 90/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.4189e-04 - val_loss: 0.0090\n",
            "Epoch 91/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.4029e-04 - val_loss: 0.0090\n",
            "Epoch 92/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 9.3789e-04 - val_loss: 0.0087\n",
            "Epoch 93/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 9.3713e-04 - val_loss: 0.0088\n",
            "Epoch 94/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.3440e-04 - val_loss: 0.0094\n",
            "Epoch 95/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 9.3410e-04 - val_loss: 0.0092\n",
            "Epoch 96/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 9.3127e-04 - val_loss: 0.0089\n",
            "Epoch 97/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 9.2809e-04 - val_loss: 0.0091\n",
            "Epoch 98/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.2925e-04 - val_loss: 0.0093\n",
            "Epoch 99/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 9.2764e-04 - val_loss: 0.0088\n",
            "Epoch 100/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.2508e-04 - val_loss: 0.0090\n",
            "Epoch 101/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 9.2212e-04 - val_loss: 0.0091\n",
            "Epoch 102/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 9.2084e-04 - val_loss: 0.0089\n",
            "Epoch 103/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.1951e-04 - val_loss: 0.0090\n",
            "Epoch 104/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.1753e-04 - val_loss: 0.0089\n",
            "Epoch 105/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 9.1752e-04 - val_loss: 0.0089\n",
            "Epoch 106/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 9.1609e-04 - val_loss: 0.0088\n",
            "Epoch 107/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.1333e-04 - val_loss: 0.0083\n",
            "Epoch 108/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 9.1577e-04 - val_loss: 0.0084\n",
            "Epoch 109/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 9.1164e-04 - val_loss: 0.0087\n",
            "Epoch 110/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.1438e-04 - val_loss: 0.0094\n",
            "Epoch 111/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 9.1212e-04 - val_loss: 0.0090\n",
            "Epoch 112/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 9.0572e-04 - val_loss: 0.0086\n",
            "Epoch 113/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 9.0840e-04 - val_loss: 0.0085\n",
            "Epoch 114/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 9.0492e-04 - val_loss: 0.0088\n",
            "Epoch 115/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 9.0317e-04 - val_loss: 0.0090\n",
            "Epoch 116/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 9.0551e-04 - val_loss: 0.0089\n",
            "Epoch 117/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 9.0453e-04 - val_loss: 0.0081\n",
            "Epoch 118/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 9.0342e-04 - val_loss: 0.0083\n",
            "Epoch 119/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 8.9767e-04 - val_loss: 0.0089\n",
            "Epoch 120/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 8.9734e-04 - val_loss: 0.0091\n",
            "Epoch 121/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 8.9586e-04 - val_loss: 0.0089\n",
            "Epoch 122/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 8.9234e-04 - val_loss: 0.0088\n",
            "Epoch 123/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 8.9129e-04 - val_loss: 0.0088\n",
            "Epoch 124/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 8.9057e-04 - val_loss: 0.0089\n",
            "Epoch 125/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 8.8851e-04 - val_loss: 0.0088\n",
            "Epoch 126/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 8.8777e-04 - val_loss: 0.0085\n",
            "Epoch 127/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 8.8740e-04 - val_loss: 0.0085\n",
            "Epoch 128/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 8.8497e-04 - val_loss: 0.0089\n",
            "Epoch 129/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 8.8578e-04 - val_loss: 0.0090\n",
            "Epoch 130/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 8.8215e-04 - val_loss: 0.0086\n",
            "Epoch 131/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 8.8099e-04 - val_loss: 0.0084\n",
            "Epoch 132/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 8.8181e-04 - val_loss: 0.0084\n",
            "Epoch 133/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 8.7934e-04 - val_loss: 0.0088\n",
            "Epoch 134/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 8.7841e-04 - val_loss: 0.0088\n",
            "Epoch 135/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 8.7763e-04 - val_loss: 0.0089\n",
            "Epoch 136/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 8.7588e-04 - val_loss: 0.0087\n",
            "Epoch 137/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 8.7554e-04 - val_loss: 0.0086\n",
            "Epoch 138/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 8.7287e-04 - val_loss: 0.0090\n",
            "Epoch 139/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 8.7217e-04 - val_loss: 0.0090\n",
            "Epoch 140/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.7259e-04 - val_loss: 0.0089\n",
            "Epoch 141/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.6767e-04 - val_loss: 0.0084\n",
            "Epoch 142/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 8.7060e-04 - val_loss: 0.0082\n",
            "Epoch 143/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 8.7014e-04 - val_loss: 0.0083\n",
            "Epoch 144/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 8.6777e-04 - val_loss: 0.0087\n",
            "Epoch 145/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.6551e-04 - val_loss: 0.0086\n",
            "Epoch 146/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.6534e-04 - val_loss: 0.0084\n",
            "Epoch 147/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 8.6266e-04 - val_loss: 0.0087\n",
            "Epoch 148/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 8.6470e-04 - val_loss: 0.0088\n",
            "Epoch 149/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.5934e-04 - val_loss: 0.0084\n",
            "Epoch 150/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 8.6092e-04 - val_loss: 0.0084\n",
            "Epoch 151/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 8.6191e-04 - val_loss: 0.0083\n",
            "Epoch 152/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 8.5787e-04 - val_loss: 0.0088\n",
            "Epoch 153/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 8.5684e-04 - val_loss: 0.0088\n",
            "Epoch 154/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 8.5508e-04 - val_loss: 0.0088\n",
            "Epoch 155/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.5339e-04 - val_loss: 0.0086\n",
            "Epoch 156/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.6099e-04 - val_loss: 0.0083\n",
            "Epoch 157/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.5223e-04 - val_loss: 0.0089\n",
            "Epoch 158/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.5238e-04 - val_loss: 0.0093\n",
            "Epoch 159/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 8.5334e-04 - val_loss: 0.0089\n",
            "Epoch 160/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 8.4632e-04 - val_loss: 0.0083\n",
            "Epoch 161/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 8.5565e-04 - val_loss: 0.0081\n",
            "Epoch 162/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 8.4691e-04 - val_loss: 0.0086\n",
            "Epoch 163/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 8.5130e-04 - val_loss: 0.0091\n",
            "Epoch 164/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 8.5013e-04 - val_loss: 0.0088\n",
            "Epoch 165/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 8.4315e-04 - val_loss: 0.0084\n",
            "Epoch 166/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 8.4638e-04 - val_loss: 0.0084\n",
            "Epoch 167/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 8.4381e-04 - val_loss: 0.0090\n",
            "Epoch 168/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 8.4174e-04 - val_loss: 0.0089\n",
            "Epoch 169/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 8.3824e-04 - val_loss: 0.0088\n",
            "Epoch 170/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 8.3646e-04 - val_loss: 0.0086\n",
            "Epoch 171/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 8.3566e-04 - val_loss: 0.0085\n",
            "Epoch 172/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 8.3465e-04 - val_loss: 0.0085\n",
            "Epoch 173/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 8.3309e-04 - val_loss: 0.0086\n",
            "Epoch 174/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 8.3197e-04 - val_loss: 0.0085\n",
            "Epoch 175/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 8.3196e-04 - val_loss: 0.0083\n",
            "Epoch 176/300\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 8.3071e-04 - val_loss: 0.0083\n",
            "Epoch 177/300\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 8.2874e-04 - val_loss: 0.0085\n",
            "Epoch 178/300\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 8.2822e-04 - val_loss: 0.0087\n",
            "Epoch 179/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 8.2710e-04 - val_loss: 0.0086\n",
            "Epoch 180/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 8.2582e-04 - val_loss: 0.0085\n",
            "Epoch 181/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 8.2600e-04 - val_loss: 0.0084\n",
            "Epoch 182/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 8.2359e-04 - val_loss: 0.0085\n",
            "Epoch 183/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 8.2179e-04 - val_loss: 0.0087\n",
            "Epoch 184/300\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 8.2289e-04 - val_loss: 0.0088\n",
            "Epoch 185/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 8.2173e-04 - val_loss: 0.0085\n",
            "Epoch 186/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 8.1931e-04 - val_loss: 0.0085\n",
            "Epoch 187/300\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 8.1901e-04 - val_loss: 0.0086\n",
            "Epoch 188/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 8.1822e-04 - val_loss: 0.0085\n",
            "Epoch 189/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 8.1592e-04 - val_loss: 0.0083\n",
            "Epoch 190/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 8.1644e-04 - val_loss: 0.0083\n",
            "Epoch 191/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 8.1485e-04 - val_loss: 0.0082\n",
            "Epoch 192/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.1550e-04 - val_loss: 0.0084\n",
            "Epoch 193/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 8.1245e-04 - val_loss: 0.0083\n",
            "Epoch 194/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.1170e-04 - val_loss: 0.0083\n",
            "Epoch 195/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.1411e-04 - val_loss: 0.0085\n",
            "Epoch 196/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 8.0891e-04 - val_loss: 0.0083\n",
            "Epoch 197/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 8.0848e-04 - val_loss: 0.0084\n",
            "Epoch 198/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 8.0719e-04 - val_loss: 0.0085\n",
            "Epoch 199/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 8.0572e-04 - val_loss: 0.0085\n",
            "Epoch 200/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.0568e-04 - val_loss: 0.0087\n",
            "Epoch 201/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.0540e-04 - val_loss: 0.0087\n",
            "Epoch 202/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 8.0367e-04 - val_loss: 0.0087\n",
            "Epoch 203/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 8.0135e-04 - val_loss: 0.0084\n",
            "Epoch 204/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 8.0294e-04 - val_loss: 0.0084\n",
            "Epoch 205/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.9999e-04 - val_loss: 0.0086\n",
            "Epoch 206/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 7.9940e-04 - val_loss: 0.0087\n",
            "Epoch 207/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.9870e-04 - val_loss: 0.0086\n",
            "Epoch 208/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 7.9739e-04 - val_loss: 0.0085\n",
            "Epoch 209/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.9704e-04 - val_loss: 0.0086\n",
            "Epoch 210/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.9498e-04 - val_loss: 0.0085\n",
            "Epoch 211/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.9351e-04 - val_loss: 0.0084\n",
            "Epoch 212/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 7.9306e-04 - val_loss: 0.0084\n",
            "Epoch 213/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.9113e-04 - val_loss: 0.0086\n",
            "Epoch 214/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 7.9029e-04 - val_loss: 0.0087\n",
            "Epoch 215/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.8961e-04 - val_loss: 0.0086\n",
            "Epoch 216/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.8880e-04 - val_loss: 0.0084\n",
            "Epoch 217/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 7.8792e-04 - val_loss: 0.0085\n",
            "Epoch 218/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 7.8535e-04 - val_loss: 0.0087\n",
            "Epoch 219/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 7.8721e-04 - val_loss: 0.0089\n",
            "Epoch 220/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.8589e-04 - val_loss: 0.0086\n",
            "Epoch 221/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.8398e-04 - val_loss: 0.0085\n",
            "Epoch 222/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.8273e-04 - val_loss: 0.0086\n",
            "Epoch 223/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.8314e-04 - val_loss: 0.0087\n",
            "Epoch 224/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 7.8094e-04 - val_loss: 0.0083\n",
            "Epoch 225/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 7.7981e-04 - val_loss: 0.0083\n",
            "Epoch 226/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.7931e-04 - val_loss: 0.0084\n",
            "Epoch 227/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 7.7825e-04 - val_loss: 0.0085\n",
            "Epoch 228/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.7635e-04 - val_loss: 0.0085\n",
            "Epoch 229/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.7500e-04 - val_loss: 0.0086\n",
            "Epoch 230/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.7422e-04 - val_loss: 0.0085\n",
            "Epoch 231/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.7501e-04 - val_loss: 0.0086\n",
            "Epoch 232/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 7.7172e-04 - val_loss: 0.0084\n",
            "Epoch 233/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 7.7144e-04 - val_loss: 0.0084\n",
            "Epoch 234/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 7.7060e-04 - val_loss: 0.0084\n",
            "Epoch 235/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 7.6903e-04 - val_loss: 0.0083\n",
            "Epoch 236/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 7.7297e-04 - val_loss: 0.0084\n",
            "Epoch 237/300\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 7.6873e-04 - val_loss: 0.0087\n",
            "Epoch 238/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 7.6807e-04 - val_loss: 0.0086\n",
            "Epoch 239/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 7.6472e-04 - val_loss: 0.0086\n",
            "Epoch 240/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 7.6372e-04 - val_loss: 0.0088\n",
            "Epoch 241/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 7.6277e-04 - val_loss: 0.0089\n",
            "Epoch 242/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 7.6426e-04 - val_loss: 0.0089\n",
            "Epoch 243/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 7.6018e-04 - val_loss: 0.0085\n",
            "Epoch 244/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 7.6330e-04 - val_loss: 0.0084\n",
            "Epoch 245/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 7.6218e-04 - val_loss: 0.0087\n",
            "Epoch 246/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 7.5848e-04 - val_loss: 0.0086\n",
            "Epoch 247/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 7.6221e-04 - val_loss: 0.0083\n",
            "Epoch 248/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 7.5674e-04 - val_loss: 0.0086\n",
            "Epoch 249/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 7.5381e-04 - val_loss: 0.0089\n",
            "Epoch 250/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 7.5503e-04 - val_loss: 0.0089\n",
            "Epoch 251/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 7.5478e-04 - val_loss: 0.0089\n",
            "Epoch 252/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 7.5361e-04 - val_loss: 0.0090\n",
            "Epoch 253/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 7.5236e-04 - val_loss: 0.0091\n",
            "Epoch 254/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 7.5057e-04 - val_loss: 0.0088\n",
            "Epoch 255/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 7.4854e-04 - val_loss: 0.0085\n",
            "Epoch 256/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 7.4859e-04 - val_loss: 0.0086\n",
            "Epoch 257/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.4698e-04 - val_loss: 0.0088\n",
            "Epoch 258/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.4609e-04 - val_loss: 0.0087\n",
            "Epoch 259/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 7.4397e-04 - val_loss: 0.0087\n",
            "Epoch 260/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.4265e-04 - val_loss: 0.0088\n",
            "Epoch 261/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 7.4356e-04 - val_loss: 0.0089\n",
            "Epoch 262/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 7.4178e-04 - val_loss: 0.0087\n",
            "Epoch 263/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.4113e-04 - val_loss: 0.0088\n",
            "Epoch 264/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 7.4225e-04 - val_loss: 0.0091\n",
            "Epoch 265/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 7.4065e-04 - val_loss: 0.0087\n",
            "Epoch 266/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.3701e-04 - val_loss: 0.0088\n",
            "Epoch 267/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.3509e-04 - val_loss: 0.0089\n",
            "Epoch 268/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.3517e-04 - val_loss: 0.0090\n",
            "Epoch 269/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 7.3252e-04 - val_loss: 0.0089\n",
            "Epoch 270/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.3280e-04 - val_loss: 0.0089\n",
            "Epoch 271/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 7.3100e-04 - val_loss: 0.0092\n",
            "Epoch 272/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.3018e-04 - val_loss: 0.0091\n",
            "Epoch 273/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.2828e-04 - val_loss: 0.0091\n",
            "Epoch 274/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 7.2746e-04 - val_loss: 0.0092\n",
            "Epoch 275/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.2740e-04 - val_loss: 0.0091\n",
            "Epoch 276/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.2462e-04 - val_loss: 0.0093\n",
            "Epoch 277/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.2392e-04 - val_loss: 0.0093\n",
            "Epoch 278/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.2438e-04 - val_loss: 0.0093\n",
            "Epoch 279/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 7.2120e-04 - val_loss: 0.0091\n",
            "Epoch 280/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 7.2239e-04 - val_loss: 0.0090\n",
            "Epoch 281/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 7.1923e-04 - val_loss: 0.0094\n",
            "Epoch 282/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.2470e-04 - val_loss: 0.0095\n",
            "Epoch 283/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.1654e-04 - val_loss: 0.0092\n",
            "Epoch 284/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.2014e-04 - val_loss: 0.0093\n",
            "Epoch 285/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 7.1478e-04 - val_loss: 0.0095\n",
            "Epoch 286/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 7.1504e-04 - val_loss: 0.0096\n",
            "Epoch 287/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 7.1247e-04 - val_loss: 0.0097\n",
            "Epoch 288/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 7.1246e-04 - val_loss: 0.0099\n",
            "Epoch 289/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.1055e-04 - val_loss: 0.0098\n",
            "Epoch 290/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 7.1269e-04 - val_loss: 0.0096\n",
            "Epoch 291/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.0762e-04 - val_loss: 0.0098\n",
            "Epoch 292/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 7.0596e-04 - val_loss: 0.0097\n",
            "Epoch 293/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.0403e-04 - val_loss: 0.0098\n",
            "Epoch 294/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.0264e-04 - val_loss: 0.0099\n",
            "Epoch 295/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 7.0120e-04 - val_loss: 0.0101\n",
            "Epoch 296/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 7.0214e-04 - val_loss: 0.0101\n",
            "Epoch 297/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 6.9865e-04 - val_loss: 0.0100\n",
            "Epoch 298/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 7.0015e-04 - val_loss: 0.0103\n",
            "Epoch 299/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 6.9600e-04 - val_loss: 0.0106\n",
            "Epoch 300/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 6.9602e-04 - val_loss: 0.0104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 과정 시각화\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(loc=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "c5hNMG7IQXu5",
        "outputId": "67a0a57f-fd91-4572-c428-e7976656020b"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict=model.predict(X_train)\n",
        "test_predict=model.predict(X_test)\n",
        "#print(X_train.shape)\n",
        "X_train.shape, X_test.shape, train_predict.shape, test_predict.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BowcRJmnAVLF",
        "outputId": "c4ac3e7d-860c-4f05-d5b3-5ae46031a15d"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 1s 6ms/step\n",
            "27/27 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1303, 60, 5), (845, 60, 5), (1303, 15), (845, 15))"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict = scaler.inverse_transform(train_predict)\n",
        "test_predict = scaler.inverse_transform(test_predict)\n",
        "original_ytrain = scaler.inverse_transform(y_train.reshape(-1,1))\n",
        "original_ytest = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "#print(test_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "24lGT_pn-QIb",
        "outputId": "e0437dc7-29af-43a9-fe84-574b020af98f"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (1303,15) (5,) (1303,15) ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-7b69c80bc8b9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moriginal_ytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moriginal_ytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(test_predict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    539\u001b[0m         )\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1303,15) (5,) (1303,15) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data R2 score:\", r2_score(original_ytrain, train_predict))\n",
        "print(\"Test data R2 score:\", r2_score(original_ytest, test_predict))"
      ],
      "metadata": {
        "id": "bkjwUtPQ-Q4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"BITCOIN_MODEL_VER2.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUcOEiDo47uI",
        "outputId": "d792184d-47e6-45d2-d5df-03f982efed1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')  # mounts the drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCaB-z4b4rkj",
        "outputId": "59a1769a-c868-4197-9636-8a5e2f5cd7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}